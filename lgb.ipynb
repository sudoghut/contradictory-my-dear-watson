{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import lightgbm as lgb\n",
    "import torch.nn as nn\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           id                                            premise  \\\n",
      "0  5130fd2cb5  and these comments were considered in formulat...   \n",
      "1  5b72532a0b  These are issues that we wrestle with in pract...   \n",
      "2  3931fbe82a  Des petites choses comme celles-là font une di...   \n",
      "3  5622f0c60b  you know they can't really defend themselves l...   \n",
      "4  86aaa48b45  ในการเล่นบทบาทสมมุติก็เช่นกัน โอกาสที่จะได้แสด...   \n",
      "\n",
      "                                          hypothesis lang_abv language  label  \n",
      "0  The rules developed in the interim were put to...       en  English      0  \n",
      "1  Practice groups are not permitted to work on t...       en  English      2  \n",
      "2              J'essayais d'accomplir quelque chose.       fr   French      0  \n",
      "3  They can't defend themselves because of their ...       en  English      0  \n",
      "4    เด็กสามารถเห็นได้ว่าชาติพันธุ์แตกต่างกันอย่างไร       th     Thai      1  \n",
      "0    5\n",
      "2    2\n",
      "1    2\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_raw = pd.read_csv('https://raw.githubusercontent.com/sudoghut/contradictory-my-dear-watson/main/data/train_10.csv')\n",
    "print(df_raw.head(5))\n",
    "print(df_raw[\"label\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    and these comments were considered in formulat...\n",
       "1    These are issues that we wrestle with in pract...\n",
       "2    Des petites choses comme celles-là font une di...\n",
       "3    you know they can't really defend themselves l...\n",
       "4    ในการเล่นบทบาทสมมุติก็เช่นกัน โอกาสที่จะได้แสด...\n",
       "5    Bir çiftlikte birisinin, ağıla kapatılmış bu ö...\n",
       "6    ریاست ہائے متحدہ امریکہ واپس آنے پر، ہج ایف بی...\n",
       "7                From Cockpit Country to St. Ann's Bay\n",
       "8    Look, it's your skin, but you're going to be i...\n",
       "Name: premise, dtype: object"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw[\"premise\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# tokenizer: https://huggingface.co/bert-base-multilingual-cased\n",
    "# tokenizer idea from: https://www.kaggle.com/code/anasofiauzsoy/tutorial-notebook/notebook\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "model = BertModel.from_pretrained(\"bert-base-multilingual-cased\")\n",
    "# text = df_raw[\"premise\"][4]\n",
    "# encoded_input = tokenizer(text, return_tensors='pt')\n",
    "# print(df_raw[\"premise\"][4])\n",
    "# print(encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [input_ids, token_type_ids, attention_mask]\n",
      "1    [input_ids, token_type_ids, attention_mask]\n",
      "2    [input_ids, token_type_ids, attention_mask]\n",
      "Name: data_embedded, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# df_raw[\"premise_embedded\"] = tokenizer(df_raw[\"premise\"], return_tensors='pt')\n",
    "\n",
    "df_raw[\"data_embedded\"] = df_raw.apply(lambda row: tokenizer(row['premise']+row['hypothesis']), axis=1)\n",
    "# df_raw[\"hypothesis_embedded\"] = df_raw.apply(lambda row: tokenizer(row['hypothesis'])[\"input_ids\"], axis=1)\n",
    "# df_raw[\"data_embedded\"] = df_raw[\"premise_embedded\"] + df_raw[\"hypothesis_embedded\"]\n",
    "# df_raw[\"data_embedded\"] = df_raw[\"data_embedded\"]\n",
    "print(df_raw[\"data_embedded\"][:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "blocks must be 2-D",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\sudos\\Dropbox\\single_projects\\kaggle\\contradictory-my-dear-watson\\lgb.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sudos/Dropbox/single_projects/kaggle/contradictory-my-dear-watson/lgb.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m train_test_split\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sudos/Dropbox/single_projects/kaggle/contradictory-my-dear-watson/lgb.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msparse\u001b[39;00m \u001b[39mimport\u001b[39;00m hstack, csr_matrix\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/sudos/Dropbox/single_projects/kaggle/contradictory-my-dear-watson/lgb.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m X_train, X_test, y_train, y_test \u001b[39m=\u001b[39m train_test_split(hstack([df_raw[[\u001b[39m\"\u001b[39;49m\u001b[39mdata_embedded\u001b[39;49m\u001b[39m\"\u001b[39;49m]]]), \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sudos/Dropbox/single_projects/kaggle/contradictory-my-dear-watson/lgb.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m                                                     df_raw[[\u001b[39m\"\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m\"\u001b[39m]], \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sudos/Dropbox/single_projects/kaggle/contradictory-my-dear-watson/lgb.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m                                                     test_size\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m, \u001b[39m# 20% test, 80% train\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sudos/Dropbox/single_projects/kaggle/contradictory-my-dear-watson/lgb.ipynb#W5sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m                                                     random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m) \u001b[39m# make the random split reproducible\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sudos/Dropbox/single_projects/kaggle/contradictory-my-dear-watson/lgb.ipynb#W5sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m(X_train[:\u001b[39m5\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\sudos\\anaconda3\\envs\\pytorch\\lib\\site-packages\\scipy\\sparse\\_construct.py:525\u001b[0m, in \u001b[0;36mhstack\u001b[1;34m(blocks, format, dtype)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mhstack\u001b[39m(blocks, \u001b[39mformat\u001b[39m\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    496\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    497\u001b[0m \u001b[39m    Stack sparse matrices horizontally (column wise)\u001b[39;00m\n\u001b[0;32m    498\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    523\u001b[0m \n\u001b[0;32m    524\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 525\u001b[0m     \u001b[39mreturn\u001b[39;00m bmat([blocks], \u001b[39mformat\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mformat\u001b[39;49m, dtype\u001b[39m=\u001b[39;49mdtype)\n",
      "File \u001b[1;32mc:\\Users\\sudos\\anaconda3\\envs\\pytorch\\lib\\site-packages\\scipy\\sparse\\_construct.py:608\u001b[0m, in \u001b[0;36mbmat\u001b[1;34m(blocks, format, dtype)\u001b[0m\n\u001b[0;32m    605\u001b[0m blocks \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(blocks, dtype\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mobject\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    607\u001b[0m \u001b[39mif\u001b[39;00m blocks\u001b[39m.\u001b[39mndim \u001b[39m!=\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m--> 608\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mblocks must be 2-D\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    610\u001b[0m M,N \u001b[39m=\u001b[39m blocks\u001b[39m.\u001b[39mshape\n\u001b[0;32m    612\u001b[0m \u001b[39m# check for fast path cases\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: blocks must be 2-D"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split([df_raw[[\"data_embedded\"]]], \n",
    "                                                    df_raw[[\"label\"]], \n",
    "                                                    test_size=0.2, # 20% test, 80% train\n",
    "                                                    random_state=42) # make the random split reproducible\n",
    "print(X_train[:5])\n",
    "# print(X_train[:3])\n",
    "# X_train.drop([0], axis=1,inplace=True)\n",
    "# y_train.drop(axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)\n",
    "\n",
    "\n",
    "X = \n",
    "[\n",
    "\tX_train[\"\"]\n",
    "]\n",
    ").tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sudos\\anaconda3\\envs\\pytorch\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "c:\\Users\\sudos\\anaconda3\\envs\\pytorch\\lib\\site-packages\\lightgbm\\basic.py:1705: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['data_embedded']\n",
      "  _log_warning('categorical_feature in Dataset is overridden.\\n'\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "DataFrame.dtypes for data must be int, float or bool.\nDid not expect the data types in the following fields: data_embedded",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\sudos\\Dropbox\\single_projects\\kaggle\\contradictory-my-dear-watson\\lgb.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 40>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sudos/Dropbox/single_projects/kaggle/contradictory-my-dear-watson/lgb.ipynb#W6sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m lgb_eval \u001b[39m=\u001b[39m lgb\u001b[39m.\u001b[39mDataset(X_test, label\u001b[39m=\u001b[39my_test, reference\u001b[39m=\u001b[39mlgb_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sudos/Dropbox/single_projects/kaggle/contradictory-my-dear-watson/lgb.ipynb#W6sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m evals_result \u001b[39m=\u001b[39m {}\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/sudos/Dropbox/single_projects/kaggle/contradictory-my-dear-watson/lgb.ipynb#W6sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m gbm \u001b[39m=\u001b[39m lgb\u001b[39m.\u001b[39;49mtrain(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sudos/Dropbox/single_projects/kaggle/contradictory-my-dear-watson/lgb.ipynb#W6sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m         params, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sudos/Dropbox/single_projects/kaggle/contradictory-my-dear-watson/lgb.ipynb#W6sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m         lgb_train,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sudos/Dropbox/single_projects/kaggle/contradictory-my-dear-watson/lgb.ipynb#W6sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m         num_boost_round\u001b[39m=\u001b[39;49m\u001b[39m3000\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sudos/Dropbox/single_projects/kaggle/contradictory-my-dear-watson/lgb.ipynb#W6sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m         valid_sets\u001b[39m=\u001b[39;49m(lgb_train, lgb_eval), \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sudos/Dropbox/single_projects/kaggle/contradictory-my-dear-watson/lgb.ipynb#W6sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m         feature_name \u001b[39m=\u001b[39;49m feature_name,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sudos/Dropbox/single_projects/kaggle/contradictory-my-dear-watson/lgb.ipynb#W6sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m         categorical_feature \u001b[39m=\u001b[39;49m feature_name_indexes,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sudos/Dropbox/single_projects/kaggle/contradictory-my-dear-watson/lgb.ipynb#W6sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m         verbose_eval\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sudos/Dropbox/single_projects/kaggle/contradictory-my-dear-watson/lgb.ipynb#W6sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m         evals_result \u001b[39m=\u001b[39;49m evals_result,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sudos/Dropbox/single_projects/kaggle/contradictory-my-dear-watson/lgb.ipynb#W6sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m         early_stopping_rounds \u001b[39m=\u001b[39;49m \u001b[39m100\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\sudos\\anaconda3\\envs\\pytorch\\lib\\site-packages\\lightgbm\\engine.py:228\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[39m# construct booster\u001b[39;00m\n\u001b[0;32m    227\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 228\u001b[0m     booster \u001b[39m=\u001b[39m Booster(params\u001b[39m=\u001b[39;49mparams, train_set\u001b[39m=\u001b[39;49mtrain_set)\n\u001b[0;32m    229\u001b[0m     \u001b[39mif\u001b[39;00m is_valid_contain_train:\n\u001b[0;32m    230\u001b[0m         booster\u001b[39m.\u001b[39mset_train_data_name(train_data_name)\n",
      "File \u001b[1;32mc:\\Users\\sudos\\anaconda3\\envs\\pytorch\\lib\\site-packages\\lightgbm\\basic.py:2229\u001b[0m, in \u001b[0;36mBooster.__init__\u001b[1;34m(self, params, train_set, model_file, model_str, silent)\u001b[0m\n\u001b[0;32m   2222\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_network(\n\u001b[0;32m   2223\u001b[0m         machines\u001b[39m=\u001b[39mmachines,\n\u001b[0;32m   2224\u001b[0m         local_listen_port\u001b[39m=\u001b[39mparams[\u001b[39m\"\u001b[39m\u001b[39mlocal_listen_port\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m   2225\u001b[0m         listen_time_out\u001b[39m=\u001b[39mparams\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mtime_out\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m120\u001b[39m),\n\u001b[0;32m   2226\u001b[0m         num_machines\u001b[39m=\u001b[39mparams[\u001b[39m\"\u001b[39m\u001b[39mnum_machines\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   2227\u001b[0m     )\n\u001b[0;32m   2228\u001b[0m \u001b[39m# construct booster object\u001b[39;00m\n\u001b[1;32m-> 2229\u001b[0m train_set\u001b[39m.\u001b[39;49mconstruct()\n\u001b[0;32m   2230\u001b[0m \u001b[39m# copy the parameters from train_set\u001b[39;00m\n\u001b[0;32m   2231\u001b[0m params\u001b[39m.\u001b[39mupdate(train_set\u001b[39m.\u001b[39mget_params())\n",
      "File \u001b[1;32mc:\\Users\\sudos\\anaconda3\\envs\\pytorch\\lib\\site-packages\\lightgbm\\basic.py:1468\u001b[0m, in \u001b[0;36mDataset.construct\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1465\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_init_score_by_predictor(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_predictor, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata, used_indices)\n\u001b[0;32m   1466\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1467\u001b[0m     \u001b[39m# create train\u001b[39;00m\n\u001b[1;32m-> 1468\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_lazy_init(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata, label\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlabel,\n\u001b[0;32m   1469\u001b[0m                     weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, group\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroup,\n\u001b[0;32m   1470\u001b[0m                     init_score\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minit_score, predictor\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_predictor,\n\u001b[0;32m   1471\u001b[0m                     silent\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msilent, feature_name\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeature_name,\n\u001b[0;32m   1472\u001b[0m                     categorical_feature\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcategorical_feature, params\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparams)\n\u001b[0;32m   1473\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfree_raw_data:\n\u001b[0;32m   1474\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sudos\\anaconda3\\envs\\pytorch\\lib\\site-packages\\lightgbm\\basic.py:1209\u001b[0m, in \u001b[0;36mDataset._lazy_init\u001b[1;34m(self, data, label, reference, weight, group, init_score, predictor, silent, feature_name, categorical_feature, params)\u001b[0m\n\u001b[0;32m   1207\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpandas_categorical \u001b[39m=\u001b[39m reference\u001b[39m.\u001b[39mpandas_categorical\n\u001b[0;32m   1208\u001b[0m     categorical_feature \u001b[39m=\u001b[39m reference\u001b[39m.\u001b[39mcategorical_feature\n\u001b[1;32m-> 1209\u001b[0m data, feature_name, categorical_feature, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpandas_categorical \u001b[39m=\u001b[39m _data_from_pandas(data,\n\u001b[0;32m   1210\u001b[0m                                                                                      feature_name,\n\u001b[0;32m   1211\u001b[0m                                                                                      categorical_feature,\n\u001b[0;32m   1212\u001b[0m                                                                                      \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpandas_categorical)\n\u001b[0;32m   1213\u001b[0m label \u001b[39m=\u001b[39m _label_from_pandas(label)\n\u001b[0;32m   1215\u001b[0m \u001b[39m# process for args\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sudos\\anaconda3\\envs\\pytorch\\lib\\site-packages\\lightgbm\\basic.py:537\u001b[0m, in \u001b[0;36m_data_from_pandas\u001b[1;34m(data, feature_name, categorical_feature, pandas_categorical)\u001b[0m\n\u001b[0;32m    535\u001b[0m bad_indices \u001b[39m=\u001b[39m _get_bad_pandas_dtypes(data\u001b[39m.\u001b[39mdtypes)\n\u001b[0;32m    536\u001b[0m \u001b[39mif\u001b[39;00m bad_indices:\n\u001b[1;32m--> 537\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mDataFrame.dtypes for data must be int, float or bool.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    538\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39mDid not expect the data types in the following fields: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    539\u001b[0m                      \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(data\u001b[39m.\u001b[39mcolumns[bad_indices]))\n\u001b[0;32m    540\u001b[0m data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mvalues\n\u001b[0;32m    541\u001b[0m \u001b[39mif\u001b[39;00m data\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mfloat32 \u001b[39mand\u001b[39;00m data\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mfloat64:\n",
      "\u001b[1;31mValueError\u001b[0m: DataFrame.dtypes for data must be int, float or bool.\nDid not expect the data types in the following fields: data_embedded"
     ]
    }
   ],
   "source": [
    "evals_result = {}\n",
    "\n",
    "# params = {\n",
    "#     'objective': 'mse',\n",
    "#     'metric': 'rmse',\n",
    "#     'num_leaves': 2 ** 7 - 1,\n",
    "#     'learning_rate': 0.005,\n",
    "#     'feature_fraction': 0.75,\n",
    "#     'bagging_fraction': 0.75,\n",
    "#     'bagging_freq': 5,\n",
    "#     'seed': 1,\n",
    "#     'verbose': 1\n",
    "# }\n",
    "params = {\n",
    "          'application': 'regression',\n",
    "          'boosting': 'gbdt',\n",
    "          'metric': 'rmse',\n",
    "          'num_leaves': 150,\n",
    "          'max_depth': -1,\n",
    "          'learning_rate': 0.01,\n",
    "          'bagging_fraction': 0.85,\n",
    "          'feature_fraction': 0.8,\n",
    "          'min_split_gain': 0.01,\n",
    "          'min_child_samples': 150,\n",
    "          'min_child_weight': 0.1,\n",
    "          'verbosity': -1,\n",
    "          'data_random_seed': 3,\n",
    "          'early_stop': 100,\n",
    "          'verbose_eval': 100,\n",
    "          'num_rounds': 3000}\n",
    "\n",
    "feature_name = X_train.columns.tolist()\n",
    "\n",
    "feature_name_indexes = ['data_embedded']\n",
    "\n",
    "lgb_train = lgb.Dataset(X_train, label=y_train)\n",
    "lgb_eval = lgb.Dataset(X_test, label=y_test, reference=lgb_train)\n",
    "\n",
    "evals_result = {}\n",
    "gbm = lgb.train(\n",
    "        params, \n",
    "        lgb_train,\n",
    "        num_boost_round=3000,\n",
    "        valid_sets=(lgb_train, lgb_eval), \n",
    "        feature_name = feature_name,\n",
    "        categorical_feature = feature_name_indexes,\n",
    "        verbose_eval=5, \n",
    "        evals_result = evals_result,\n",
    "        early_stopping_rounds = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot initialize Dataset from Series",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\sudos\\anaconda3\\envs\\pytorch\\lib\\site-packages\\scipy\\sparse\\_base.py:376\u001b[0m, in \u001b[0;36mspmatrix.asformat\u001b[1;34m(self, format, copy)\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 376\u001b[0m     \u001b[39mreturn\u001b[39;00m convert_method(copy\u001b[39m=\u001b[39;49mcopy)\n\u001b[0;32m    377\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\sudos\\anaconda3\\envs\\pytorch\\lib\\site-packages\\scipy\\sparse\\_coo.py:402\u001b[0m, in \u001b[0;36mcoo_matrix.tocsr\u001b[1;34m(self, copy)\u001b[0m\n\u001b[0;32m    401\u001b[0m indices \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty_like(col, dtype\u001b[39m=\u001b[39midx_dtype)\n\u001b[1;32m--> 402\u001b[0m data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty_like(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata, dtype\u001b[39m=\u001b[39mupcast(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdtype))\n\u001b[0;32m    404\u001b[0m coo_tocsr(M, N, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnnz, row, col, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata,\n\u001b[0;32m    405\u001b[0m           indptr, indices, data)\n",
      "File \u001b[1;32mc:\\Users\\sudos\\anaconda3\\envs\\pytorch\\lib\\site-packages\\scipy\\sparse\\_sputils.py:50\u001b[0m, in \u001b[0;36mupcast\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[39mreturn\u001b[39;00m t\n\u001b[1;32m---> 50\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mno supported conversion for types: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m (args,))\n",
      "\u001b[1;31mTypeError\u001b[0m: no supported conversion for types: (dtype('O'),)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\sudos\\anaconda3\\envs\\pytorch\\lib\\site-packages\\lightgbm\\basic.py:1277\u001b[0m, in \u001b[0;36mDataset._lazy_init\u001b[1;34m(self, data, label, reference, weight, group, init_score, predictor, silent, feature_name, categorical_feature, params)\u001b[0m\n\u001b[0;32m   1276\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1277\u001b[0m     csr \u001b[39m=\u001b[39m scipy\u001b[39m.\u001b[39;49msparse\u001b[39m.\u001b[39;49mcsr_matrix(data)\n\u001b[0;32m   1278\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__init_from_csr(csr, params_str, ref_dataset)\n",
      "File \u001b[1;32mc:\\Users\\sudos\\anaconda3\\envs\\pytorch\\lib\\site-packages\\scipy\\sparse\\_compressed.py:84\u001b[0m, in \u001b[0;36m_cs_matrix.__init__\u001b[1;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39munrecognized \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m_matrix constructor usage\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     83\u001b[0m                          \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mformat)) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m---> 84\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_self(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__class__\u001b[39;49m(\n\u001b[0;32m     85\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_coo_container(arg1, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m     86\u001b[0m     ))\n\u001b[0;32m     88\u001b[0m \u001b[39m# Read matrix dimensions given, if any\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sudos\\anaconda3\\envs\\pytorch\\lib\\site-packages\\scipy\\sparse\\_compressed.py:33\u001b[0m, in \u001b[0;36m_cs_matrix.__init__\u001b[1;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 33\u001b[0m     arg1 \u001b[39m=\u001b[39m arg1\u001b[39m.\u001b[39;49masformat(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mformat)\n\u001b[0;32m     34\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_self(arg1)\n",
      "File \u001b[1;32mc:\\Users\\sudos\\anaconda3\\envs\\pytorch\\lib\\site-packages\\scipy\\sparse\\_base.py:378\u001b[0m, in \u001b[0;36mspmatrix.asformat\u001b[1;34m(self, format, copy)\u001b[0m\n\u001b[0;32m    377\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m--> 378\u001b[0m     \u001b[39mreturn\u001b[39;00m convert_method()\n",
      "File \u001b[1;32mc:\\Users\\sudos\\anaconda3\\envs\\pytorch\\lib\\site-packages\\scipy\\sparse\\_coo.py:402\u001b[0m, in \u001b[0;36mcoo_matrix.tocsr\u001b[1;34m(self, copy)\u001b[0m\n\u001b[0;32m    401\u001b[0m indices \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty_like(col, dtype\u001b[39m=\u001b[39midx_dtype)\n\u001b[1;32m--> 402\u001b[0m data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty_like(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata, dtype\u001b[39m=\u001b[39mupcast(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdtype))\n\u001b[0;32m    404\u001b[0m coo_tocsr(M, N, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnnz, row, col, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata,\n\u001b[0;32m    405\u001b[0m           indptr, indices, data)\n",
      "File \u001b[1;32mc:\\Users\\sudos\\anaconda3\\envs\\pytorch\\lib\\site-packages\\scipy\\sparse\\_sputils.py:50\u001b[0m, in \u001b[0;36mupcast\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[39mreturn\u001b[39;00m t\n\u001b[1;32m---> 50\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mno supported conversion for types: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m (args,))\n",
      "\u001b[1;31mTypeError\u001b[0m: no supported conversion for types: (dtype('O'),)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\sudos\\Dropbox\\single_projects\\kaggle\\contradictory-my-dear-watson\\lgb.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/sudos/Dropbox/single_projects/kaggle/contradictory-my-dear-watson/lgb.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m gbm \u001b[39m=\u001b[39m lgb\u001b[39m.\u001b[39;49mtrain(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sudos/Dropbox/single_projects/kaggle/contradictory-my-dear-watson/lgb.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m         params, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sudos/Dropbox/single_projects/kaggle/contradictory-my-dear-watson/lgb.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m         lgb_train,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sudos/Dropbox/single_projects/kaggle/contradictory-my-dear-watson/lgb.ipynb#X10sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m         num_boost_round\u001b[39m=\u001b[39;49m\u001b[39m3000\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sudos/Dropbox/single_projects/kaggle/contradictory-my-dear-watson/lgb.ipynb#X10sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m         valid_sets\u001b[39m=\u001b[39;49m(lgb_train, lgb_eval), \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sudos/Dropbox/single_projects/kaggle/contradictory-my-dear-watson/lgb.ipynb#X10sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m         verbose_eval\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sudos/Dropbox/single_projects/kaggle/contradictory-my-dear-watson/lgb.ipynb#X10sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m         evals_result \u001b[39m=\u001b[39;49m evals_result,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sudos/Dropbox/single_projects/kaggle/contradictory-my-dear-watson/lgb.ipynb#X10sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m         early_stopping_rounds \u001b[39m=\u001b[39;49m \u001b[39m100\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\sudos\\anaconda3\\envs\\pytorch\\lib\\site-packages\\lightgbm\\engine.py:228\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[39m# construct booster\u001b[39;00m\n\u001b[0;32m    227\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 228\u001b[0m     booster \u001b[39m=\u001b[39m Booster(params\u001b[39m=\u001b[39;49mparams, train_set\u001b[39m=\u001b[39;49mtrain_set)\n\u001b[0;32m    229\u001b[0m     \u001b[39mif\u001b[39;00m is_valid_contain_train:\n\u001b[0;32m    230\u001b[0m         booster\u001b[39m.\u001b[39mset_train_data_name(train_data_name)\n",
      "File \u001b[1;32mc:\\Users\\sudos\\anaconda3\\envs\\pytorch\\lib\\site-packages\\lightgbm\\basic.py:2229\u001b[0m, in \u001b[0;36mBooster.__init__\u001b[1;34m(self, params, train_set, model_file, model_str, silent)\u001b[0m\n\u001b[0;32m   2222\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_network(\n\u001b[0;32m   2223\u001b[0m         machines\u001b[39m=\u001b[39mmachines,\n\u001b[0;32m   2224\u001b[0m         local_listen_port\u001b[39m=\u001b[39mparams[\u001b[39m\"\u001b[39m\u001b[39mlocal_listen_port\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m   2225\u001b[0m         listen_time_out\u001b[39m=\u001b[39mparams\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mtime_out\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m120\u001b[39m),\n\u001b[0;32m   2226\u001b[0m         num_machines\u001b[39m=\u001b[39mparams[\u001b[39m\"\u001b[39m\u001b[39mnum_machines\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   2227\u001b[0m     )\n\u001b[0;32m   2228\u001b[0m \u001b[39m# construct booster object\u001b[39;00m\n\u001b[1;32m-> 2229\u001b[0m train_set\u001b[39m.\u001b[39;49mconstruct()\n\u001b[0;32m   2230\u001b[0m \u001b[39m# copy the parameters from train_set\u001b[39;00m\n\u001b[0;32m   2231\u001b[0m params\u001b[39m.\u001b[39mupdate(train_set\u001b[39m.\u001b[39mget_params())\n",
      "File \u001b[1;32mc:\\Users\\sudos\\anaconda3\\envs\\pytorch\\lib\\site-packages\\lightgbm\\basic.py:1468\u001b[0m, in \u001b[0;36mDataset.construct\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1465\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_init_score_by_predictor(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_predictor, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata, used_indices)\n\u001b[0;32m   1466\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1467\u001b[0m     \u001b[39m# create train\u001b[39;00m\n\u001b[1;32m-> 1468\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_lazy_init(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata, label\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlabel,\n\u001b[0;32m   1469\u001b[0m                     weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, group\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroup,\n\u001b[0;32m   1470\u001b[0m                     init_score\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minit_score, predictor\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_predictor,\n\u001b[0;32m   1471\u001b[0m                     silent\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msilent, feature_name\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeature_name,\n\u001b[0;32m   1472\u001b[0m                     categorical_feature\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcategorical_feature, params\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparams)\n\u001b[0;32m   1473\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfree_raw_data:\n\u001b[0;32m   1474\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sudos\\anaconda3\\envs\\pytorch\\lib\\site-packages\\lightgbm\\basic.py:1280\u001b[0m, in \u001b[0;36mDataset._lazy_init\u001b[1;34m(self, data, label, reference, weight, group, init_score, predictor, silent, feature_name, categorical_feature, params)\u001b[0m\n\u001b[0;32m   1278\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__init_from_csr(csr, params_str, ref_dataset)\n\u001b[0;32m   1279\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m:\n\u001b[1;32m-> 1280\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mCannot initialize Dataset from \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mtype\u001b[39m(data)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m))\n\u001b[0;32m   1281\u001b[0m \u001b[39mif\u001b[39;00m label \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1282\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_label(label)\n",
      "\u001b[1;31mTypeError\u001b[0m: Cannot initialize Dataset from Series"
     ]
    }
   ],
   "source": [
    "# gbm = lgb.train(\n",
    "#         params, \n",
    "#         lgb_train,\n",
    "#         num_boost_round=3000,\n",
    "#         valid_sets=(lgb_train, lgb_eval), \n",
    "#         verbose_eval=5, \n",
    "#         evals_result = evals_result,\n",
    "#         early_stopping_rounds = 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "047a54d6d5df71c45a9c123b62e463480937259cb8383da567628524d0beb982"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
