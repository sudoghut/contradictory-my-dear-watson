{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sudos\\anaconda3\\envs\\pytorch\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import lightgbm as lgb\n",
    "import torch.nn as nn\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           id                                            premise  \\\n",
      "0  5130fd2cb5  and these comments were considered in formulat...   \n",
      "1  5b72532a0b  These are issues that we wrestle with in pract...   \n",
      "2  3931fbe82a  Des petites choses comme celles-là font une di...   \n",
      "3  5622f0c60b  you know they can't really defend themselves l...   \n",
      "4  86aaa48b45  ในการเล่นบทบาทสมมุติก็เช่นกัน โอกาสที่จะได้แสด...   \n",
      "\n",
      "                                          hypothesis lang_abv language  label  \n",
      "0  The rules developed in the interim were put to...       en  English      0  \n",
      "1  Practice groups are not permitted to work on t...       en  English      2  \n",
      "2              J'essayais d'accomplir quelque chose.       fr   French      0  \n",
      "3  They can't defend themselves because of their ...       en  English      0  \n",
      "4    เด็กสามารถเห็นได้ว่าชาติพันธุ์แตกต่างกันอย่างไร       th     Thai      1  \n",
      "0    5\n",
      "2    2\n",
      "1    2\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_raw = pd.read_csv('https://raw.githubusercontent.com/sudoghut/contradictory-my-dear-watson/main/data/train_10.csv')\n",
    "print(df_raw.head(5))\n",
    "print(df_raw[\"label\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    and these comments were considered in formulat...\n",
       "1    These are issues that we wrestle with in pract...\n",
       "2    Des petites choses comme celles-là font une di...\n",
       "3    you know they can't really defend themselves l...\n",
       "4    ในการเล่นบทบาทสมมุติก็เช่นกัน โอกาสที่จะได้แสด...\n",
       "5    Bir çiftlikte birisinin, ağıla kapatılmış bu ö...\n",
       "6    ریاست ہائے متحدہ امریکہ واپس آنے پر، ہج ایف بی...\n",
       "7                From Cockpit Country to St. Ann's Bay\n",
       "8    Look, it's your skin, but you're going to be i...\n",
       "Name: premise, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw[\"premise\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ในการเล่นบทบาทสมมุติก็เช่นกัน โอกาสที่จะได้แสดงออกและได้เล่นหลายบทบาทไปพร้อมกัน ๆ อาจช่วยให้เด็กจับความคล้ายคลึงและความแตกต่างระหว่างผู้คนในด้านความปรารถนา ความเชื่อ และความรู้สึกได้\n",
      "{'input_ids': tensor([[   101,  46301,  53123, 111431,  20507,  34523,  49097,  37022,  49097,\n",
      "         107854,  28767,  17405,  17405,  53936,  80275,  18427, 111437, 111431,\n",
      "          42407,  34523,  89969,   1452,  63667,  17344,  28767,  18203,  46856,\n",
      "          22598, 111435,  81831, 111432,  28767,  82275,  33178,  63667, 111432,\n",
      "          20507,  22598, 111435,  81831, 111431,  20507,  34523, 111424,  61888,\n",
      "          20503,  49097,  37022,  49097, 107854, 111435,  49292,  39901,  22765,\n",
      "          35933,  33178,  17405,  89969,   1455,   1436,  17344,  46856,  42407,\n",
      "          31904,  31287,  20503, 111434, 111424,  35933, 111431,  22123, 111437,\n",
      "          18427,  46856, 102269,  31256,  31287,  79790,  31256,  20507,  43102,\n",
      "          20503,  31256,  20507, 111428,  19197, 111432,  20507,  22598,  31256,\n",
      "          31287,  79790, 111432,  30011,  18427,  30011,  38999,  19197,  22765,\n",
      "          22598, 111424,  26131,  19197, 111420,  38468,  35933,  31256,  16000,\n",
      "          75890,  81831,  44121,  31256,  31287,  79790,  49292,  22765,  52780,\n",
      "         111419,  62904,   1397,  31287,  79790, 111431,  42407,  48207,  15493,\n",
      "          31256,  31287,  79790,  22765,  38468,  35933,  28767, 111428,  18427,\n",
      "         111435,  81831,    102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "# tokenizer: https://huggingface.co/bert-base-multilingual-cased\n",
    "# tokenizer idea from: https://www.kaggle.com/code/anasofiauzsoy/tutorial-notebook/notebook\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "model = BertModel.from_pretrained(\"bert-base-multilingual-cased\")\n",
    "text = df_raw[\"premise\"][4]\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "# output = model(**encoded_input)\n",
    "print(df_raw[\"premise\"][4])\n",
    "print(encoded_input)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "047a54d6d5df71c45a9c123b62e463480937259cb8383da567628524d0beb982"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
